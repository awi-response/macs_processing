{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23562b0-325f-4808-918e-ed79bec8f1a5",
   "metadata": {},
   "source": [
    "# Create Product report for MACS processing data\n",
    "\n",
    "## 1. Data loading\n",
    "\n",
    "## 2. File checks\n",
    "* check completeness of input dirs and base files\n",
    "* count tiles\n",
    "* control for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b5091-985a-4a15-bfd5-c1f79db304ea",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5206242-ef63-4cea-b577-41427f27bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import shutil\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils_report import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf4314d-c4be-49a5-848c-be74ab276e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vrt_is_linux(row):\n",
    "    return all([vrt_is_linux(row['products_dir'] / item) for item in ['Ortho.vrt', 'DSM.vrt']])\n",
    "\n",
    "def vrt_is_linux(vrt_file):\n",
    "    with open(vrt_file, 'r') as src:\n",
    "        txt = src.readlines()\n",
    "        n_win_ds = len([True for line in txt if '\\\\' in line])\n",
    "    return n_win_ds == 0\n",
    "\n",
    "def vrt_win_to_linux(infile, outfile):\n",
    "        # open file and replace if necessary\n",
    "        with open(infile, 'r') as src:\n",
    "            txt = src.readlines()\n",
    "            txt_updated = [line.replace('\\\\', '/') for line in txt]\n",
    "\n",
    "        with open(outfile, 'w') as tgt:\n",
    "            tgt.writelines(txt_updated)\n",
    "\n",
    "def vrt_transform_win_to_linux(vrt_file, backup=False):\n",
    "    \n",
    "    # check if already linux vrt file\n",
    "    if not vrt_is_linux(vrt_file):\n",
    "        \n",
    "        # create name\n",
    "        vrt_file_updated = vrt_file.parent / (vrt_file.stem + '_new.vrt')\n",
    "        vrt_file_backup = vrt_file.parent / (vrt_file.stem + '_backup.vrt')\n",
    "        \n",
    "        # open file and replace if necessary\n",
    "        vrt_win_to_linux(vrt_file, vrt_file_updated)\n",
    "\n",
    "        # renaming\n",
    "        if backup:\n",
    "            shutil.copy2(vrt_file, vrt_file_backup)\n",
    "        os.remove(vrt_file)\n",
    "        os.rename(vrt_file_updated, vrt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081d2f16-f4be-42f5-b34f-fc8326d55414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aoi_area(row):\n",
    "    filename = DIR_AOI / (row.project_name + '.geojson') \n",
    "    gdf = gpd.read_file(filename).to_crs(epsg=32604)\n",
    "    return (gdf.geometry.area / 1e6).round(2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ade324-13a4-4d8a-8b8c-3c2c0f9a2a4d",
   "metadata": {},
   "source": [
    "## Setup \n",
    "* paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76073d9f-08dd-4e1f-95ce-7d9bb7aac46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup basepaths\n",
    "DIR_BASE = Path(r'S:\\p_macsprocessing')\n",
    "DIR_DATA_PRODUCTS = DIR_BASE / 'data_products'\n",
    "DIR_AOI = DIR_BASE / 'aoi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99afb2d-174d-4c1d-a4f7-a8f0ca4ebdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if directories all exists\n",
    "for d in [DIR_BASE, DIR_DATA_PRODUCTS, DIR_AOI]:\n",
    "    assert d.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3357150-9634-4c14-aab5-0397cf863258",
   "metadata": {},
   "source": [
    "## Calculate Statistics \n",
    "* Files\n",
    "* File Count\n",
    "* file count accross types\n",
    "* aoi (size?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318f924-0d99-445d-bfaa-11ffa71aa465",
   "metadata": {},
   "source": [
    "#### Setup basic Dataframe and split input name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecca8a9a-49a5-4540-b8da-d4a93d8e4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['project_name', 'products_dir'])\n",
    "# create pathlist of output products\n",
    "dir_list = list(DIR_DATA_PRODUCTS.glob('*'))\n",
    "df['products_dir'] = dir_list\n",
    "# get project name\n",
    "df['project_name'] = df['products_dir'].apply(lambda x: x.name)\n",
    "# add site specific details\n",
    "df = split_name_details(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86b90466-ff9b-452a-968f-0a36246f35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check ortho, dsm and processing_info\n",
    "file_check_columns = ['DSM', 'Ortho','processing_info']\n",
    "cols_file_check = flatten([[f\"{item}_dir_exists\", f\"{item}_n_files\"] for item in file_check_columns])\n",
    "\n",
    "file_check_output = df.apply(file_check, dirs=file_check_columns, axis=1)\n",
    "df = df.join(pd.DataFrame(file_check_output.to_list(), columns=cols_file_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "463984ba-f1a1-4384-b71f-9a269a72910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if aoi exists\n",
    "df['aoi_exists'] = df.apply(lambda x: (DIR_AOI / f'{x.project_name}.geojson').exists(), axis=1)\n",
    "df['aoi_area_km2'] = df.apply(calculate_aoi_area, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06eb10d6-030a-40a3-b165-be6609e82ca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'progress_apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mjoin(pd\u001b[38;5;241m.\u001b[39mDataFrame(PC_files\u001b[38;5;241m.\u001b[39mto_list(), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPointCloudsRGB_n_files\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPointCloudsNIR_n_files\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# get mean point cloud density\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m(get_median_point_density, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\.conda\\envs\\MACS37\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5581\u001b[0m ):\n\u001b[0;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'progress_apply'"
     ]
    }
   ],
   "source": [
    "# check point cloud files\n",
    "PC_files = df.iloc[:].apply(file_check_PC, dirs=['PointClouds'], axis=1)\n",
    "df = df.join(pd.DataFrame(PC_files.to_list(), columns=['PointCloudsRGB_n_files', 'PointCloudsNIR_n_files']))\n",
    "# get mean point cloud density\n",
    "df = df.join(df.iloc[:].apply(get_median_point_density, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e289fc-5b9e-4fdc-8930-b7e3285fa8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for base files\n",
    "# has vrt files\n",
    "df['vrt_exists'] = df.apply(check_files_vrt, axis=1)\n",
    "# has previews\n",
    "df['previews_exists'] = df.apply(check_files_previews, axis=1)\n",
    "# has previews\n",
    "df['footprints_exists'] = df.apply(check_files_footprints, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcda499-1e13-4108-b9a5-6e6aaf7a3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vrt_is_linux'] = df.apply(check_vrt_is_linux, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef0533-0e99-46ab-82cd-cd9ca7e28aa5",
   "metadata": {},
   "source": [
    "#### File counts in subdirs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b822bf-5b3e-4b4d-b74f-5cce35d69f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = check_file_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb53c2d-4821-4b3f-b117-3a4d5f4f8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585ea4a4-069e-4b75-98f7-48056f888693",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbd8e2-ad44-4e91-a45f-bb7cf2535fd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Export\n",
    "* colored df\n",
    "* csv\n",
    "* pdf\n",
    "* excel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c70ff-4beb-4f77-b58a-a02ee7805ac6",
   "metadata": {},
   "source": [
    "#### Create styling by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0e74d-6328-41af-ad3a-716bff79b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['valid_count_dsm_ortho_equal'] = df['DSM_n_files'] == df['Ortho_n_files']\n",
    "df['valid_count_pcrgb_pcnir_equal'] = df['PointCloudsRGB_n_files'] == df['PointCloudsNIR_n_files']\n",
    "#df['valid_count_pc_raster_equal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e52ec8-b8f3-465f-96db-f4d77eaf6a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa15f1e-074b-4f10-b44c-b58ad719d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subsets for styling\n",
    "subset_round = [s for s in df.columns if s.endswith('_density')] + ['aoi_area_km2']\n",
    "subset_cols = [s for s in df.columns if s.endswith('n_files')] + subset_round\n",
    "subset_exists = [s for s in df.columns if s.endswith('_exists')]\n",
    "subset_valid_counts =  [s for s in df.columns if s.startswith('valid_count_')]\n",
    "subset_valid_styler = ['project_name', 'products_dir', 'all_valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c62394-869e-4679-9256-96162b5cf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_valid'] = df[subset_exists + subset_valid_counts].all(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0df978-1686-4f34-985f-638584e96a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styled = df.style.background_gradient(cmap='Blues', subset=subset_cols[:], axis=0)\\\n",
    ".background_gradient(cmap='Greens', subset=subset_exists, axis=0, vmin=0, vmax=1)\\\n",
    ".applymap(highlight_zero)\\\n",
    ".apply(highlight_invalid, axis=1, subset=subset_valid_styler)\\\n",
    ".format('{:.2f}', subset=subset_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4aa29e-0e26-4559-b15d-cfbd50a70513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(DIR_BASE / 'processing_status_report_raw.z')\n",
    "df_styled.to_html(DIR_BASE / 'processing_status_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ebc47-1f54-4de0-91c1-940a2b559e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "684888cf-fbc3-4ca3-9eb4-a645a35d9e99",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d159114-90c7-4d36-9d3c-8947d4d4b810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
